# üî• News

<div class="year-badge">
  <b>2025üêç</b>
</div>
<ul class="news-timeline">
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">12/2025</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--industry"><i class="fas fa-industry" aria-hidden="true"></i>Industry:</span>
    </span>
    <span class="news-text">Our IQA solution has been deployed at <strong>OPPO</strong> in practical production. It transforms assessment from a subjective process into an objective one and reduces the evaluation workload from approximately <strong>two person-days</strong> to <strong>0.1 person-days</strong>.</span>
  </li>
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">07/2025</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--talk"><i class="fas fa-microphone" aria-hidden="true"></i>Talk:</span>
    </span>
    <span class="news-text">We were invited to give a talk at <strong>Apple Inc.</strong> Ô£ø.</span>
  </li>
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">04/2025</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--paper"><i class="fas fa-file-alt" aria-hidden="true"></i>Paper:</span>
    </span>
    <span class="news-text">Our work <em>Visual-Instructed Degradation Diffusion for All-in-One Image Restoration</em> was accepted by The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025 (<a class="news-venue" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Visual-Instructed_Degradation_Diffusion_for_All-in-One_Image_Restoration_CVPR_2025_paper.pdf">CVPR 2025</a>).</span>
  </li>
</ul>

<div class="year-badge">
  <b>2024üê≤</b>
</div>
<ul class="news-timeline">
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">12/2024</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--talk"><i class="fas fa-microphone" aria-hidden="true"></i>Talk:</span>
    </span>
    <span class="news-text">We were invited to give a talk at <strong>DJI Inc.</strong></span>
  </li>
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">08/2024</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--paper"><i class="fas fa-file-alt" aria-hidden="true"></i>Paper:</span>
    </span>
    <span class="news-text">Our work <em>MobileIQA: Exploiting Mobile-level Diverse Opinion Network For No-Reference Image Quality Assessment Using Knowledge Distillation</em> was accepted by The 18th European Conference on Computer Vision Workshop (<a class="news-venue" href="https://dl.acm.org/doi/10.1007/978-3-031-91856-8_1">ECCVW 2024</a>).</span>
  </li>
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">07/2024</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--paper"><i class="fas fa-file-alt" aria-hidden="true"></i>Paper:</span>
    </span>
    <span class="news-text">Our work <em>PromptIQA: Boosting the Performance and Generalization for No-Reference Image Quality Assessment via Prompts</em> was accepted by The 18th European Conference on Computer Vision (<a class="news-venue" href="https://link.springer.com/chapter/10.1007/978-3-031-73232-4_14">ECCV 2024</a>).</span>
  </li>
</ul>

<div class="year-badge">
  <b>2023üê∞</b>
</div>
<ul class="news-timeline">
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">08/2023</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--award"><i class="fas fa-trophy" aria-hidden="true"></i>Award:</span>
    </span>
    <span class="news-text">We won the <strong>second prize</strong> in the "AIGC Inference Performance Optimisation Track" held by <strong>Baidu</strong>.</span>
  </li>
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">07/2023</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--paper"><i class="fas fa-file-alt" aria-hidden="true"></i>Paper:</span>
    </span>
    <span class="news-text">Our work <em>Hierarchical Curriculum Learning for No-reference Image Quality Assessment</em> was accepted by International Journal of Computer Vision (<a class="news-venue" href="https://link.springer.com/article/10.1007/s11263-023-01851-5">IJCV</a>).</span>
  </li>
</ul>

<div class="year-badge">
  <b>2022üêØ</b>
</div>
<ul class="news-timeline">
  <li class="news-timeline__item">
    <span class="news-meta">
      <span class="news-date">09/2022</span>
      <span class="news-sep">-</span>
      <span class="news-tag news-tag--paper"><i class="fas fa-file-alt" aria-hidden="true"></i>Paper:</span>
    </span>
    <span class="news-text">Our work <em>Teacher-Guided Learning for Blind Image Quality Assessment</em> was accepted by The 16th Asian Conference on Computer Vision (<a class="news-venue" href="https://openaccess.thecvf.com/content/ACCV2022/html/Chen_Teacher-Guided_Learning_for_Blind_Image_Quality_Assessment_ACCV_2022_paper.html">ACCV 2022</a>).</span>
  </li>
</ul>
